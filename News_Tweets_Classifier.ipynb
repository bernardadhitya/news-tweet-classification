{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News_Tweets_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjYjVIM8aI67"
      },
      "source": [
        "# News Tweets Classifier\n",
        "Reference:\n",
        "- https://iq.opengenus.org/text-classification-using-k-nearest-neighbors/\n",
        "- https://www.geeksforgeeks.org/saving-a-machine-learning-model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9JGq7zHaOQn"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52en3cjUZ1kc",
        "outputId": "5a4677ee-c11f-493d-cfe4-8d87717f03bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLb8uen0aJIK"
      },
      "source": [
        "Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ6IPV-dabWO",
        "outputId": "55ad32a4-4e76-4266-8dc3-a55c4a36be11"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RjNWJ20chfa"
      },
      "source": [
        "Import and preprocess dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n26FXYXckmC"
      },
      "source": [
        "FILENAME = \"/content/drive/My Drive/News Tweets Classifier/news_tweets_labeled.csv\"\n",
        "df = pd.read_csv(FILENAME)\n",
        "df = df[[\"text\", \"category\"]]\n",
        "# df = df.sort_values([\"category\", \"text\"], ascending=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AkjZg8jxL6H"
      },
      "source": [
        "sw = stopwords.words('english')\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "for i in range(df.shape[0]):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', df.loc[i, 'text'])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "\n",
        "  review = [wnl.lemmatize(word) for word in review if not word in sw]\n",
        "  review = ' '.join(review)\n",
        "  df.loc[i, 'text'] = review"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX_yvDbGc8SE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041c92fa-11b9-4aee-b548-aee1b595cb56"
      },
      "source": [
        "df = df[:3000]\n",
        "print(df.groupby('category').count())\n",
        "train_data = df.sample(frac=0.8, random_state=200)\n",
        "test_data = df.drop(train_data.index)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               text\n",
            "category           \n",
            "business        290\n",
            "entertainment   250\n",
            "health          283\n",
            "lifestyle       326\n",
            "others          808\n",
            "politics        596\n",
            "science         126\n",
            "sport           216\n",
            "technology       52\n",
            "weather          53\n",
            "2400\n",
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHNdHAtweQ4b"
      },
      "source": [
        "Build dictionary and transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3WkZ_kaeVYF"
      },
      "source": [
        "# Builds a dictionary of features and transforms document to feature vectors and convert tweets to a \n",
        "# matrix of token counts (CountVectorizer)\n",
        "count_vect = CountVectorizer()\n",
        "x_train_counts = count_vect.fit_transform(train_data['text'])\n",
        "\n",
        "# Transform a count matrix to a normalized tf-idf representation (tf-idf transformer)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cScZpVUMggUN"
      },
      "source": [
        "Train the model and give some new tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-2JdqdPgDjG"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
        "\n",
        "# Train classifier; train_data['category'] will be having numbers assigned for each category in train data\n",
        "clf = knn.fit(x_train_tfidf, train_data['category'])\n",
        "\n",
        "# Input data to predict their classes of the given categories\n",
        "tweets_new = [\"Seven people have been arrested following a search of two vehicles in Hayle Cornwall police have said\", \n",
        "            \"RT MoneyTelegraph Your gas and electricity bills are set to increase by 36pc over the next 10 years\",\n",
        "            \"The most common symptom of Covid19 is now a headache say experts as they warned people to get tested even if they think they are not suffering from the illness\"]\n",
        "# building up feature vector of input\n",
        "x_new_counts = count_vect.transform(tweets_new)\n",
        "# Call transform instead of fit_transform because it's already been fit\n",
        "x_new_tfidf = tfidf_transformer.transform(x_new_counts)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXqP7i0YiWo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bd26fa-17d8-4934-c026-879764605553"
      },
      "source": [
        "# Predicting the category of input text: Will give out number of category\n",
        "predicted = clf.predict(x_new_tfidf)\n",
        "\n",
        "for doc, category in zip(tweets_new, predicted):\n",
        "  print('%r => %s' %(doc, category))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Seven people have been arrested following a search of two vehicles in Hayle Cornwall police have said' => others\n",
            "'RT MoneyTelegraph Your gas and electricity bills are set to increase by 36pc over the next 10 years' => business\n",
            "'The most common symptom of Covid19 is now a headache say experts as they warned people to get tested even if they think they are not suffering from the illness' => health\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpSQ4x2Bp47O"
      },
      "source": [
        "Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne_xXqtgp6EP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0e1919-811e-4afc-fe10-b504bdc1607d"
      },
      "source": [
        "# use Pipeline to add vectorizer -> transformer -> classifier all in a one compound classifier\n",
        "tweet_clf = Pipeline([\n",
        "  ('vect', CountVectorizer()),\n",
        "  ('tfidf', TfidfTransformer()),\n",
        "  ('clf', knn)\n",
        "])\n",
        "\n",
        "# Fitting train data to the pipeline\n",
        "tweet_clf.fit(train_data['text'], train_data['category'])\n",
        "\n",
        "# Test data\n",
        "docs_test = test_data['text']\n",
        "\n",
        "# Predicting test data\n",
        "predicted = tweet_clf.predict(docs_test)\n",
        "print('We got an accuracy of', np.mean(predicted == test_data['category']) * 100, '% over the test data.')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We got an accuracy of 75.5 % over the test data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziufDO9gxbdd"
      },
      "source": [
        "false_pred = []\n",
        "\n",
        "for i, pred in enumerate(predicted):\n",
        "  if str(pred) != str(test_data.iloc[i]['category']):\n",
        "    false_pred.append(test_data.iloc[i])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CvyZhgmbykjx",
        "outputId": "3bb9601c-f298-4d3a-9a06-314e8cc5f4d9"
      },
      "source": [
        "false_pred = pd.DataFrame(false_pred)\n",
        "false_pred"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>north korean leader kim jong un bigger problem...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>another lawsuit challenging affordable care ac...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>want know happened january th join drew griffi...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>much emphasis placed onworries able get back s...</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>civil complaint alleges pornhub parent company...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2902</th>\n",
              "      <td>rt bbcnews british woman overjoyed becoming gr...</td>\n",
              "      <td>lifestyle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2913</th>\n",
              "      <td>airbnb reportedly pay tourist rape</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>e nintendo show zelda breath wild</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>irish scientist identify covid patient develop...</td>\n",
              "      <td>health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2977</th>\n",
              "      <td>marjorie taylor greene sorry likening mask hol...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>147 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text       category\n",
              "124   north korean leader kim jong un bigger problem...       politics\n",
              "162   another lawsuit challenging affordable care ac...       politics\n",
              "174   want know happened january th join drew griffi...       politics\n",
              "184   much emphasis placed onworries able get back s...         others\n",
              "185   civil complaint alleges pornhub parent company...       business\n",
              "...                                                 ...            ...\n",
              "2902  rt bbcnews british woman overjoyed becoming gr...      lifestyle\n",
              "2913                 airbnb reportedly pay tourist rape       business\n",
              "2943                  e nintendo show zelda breath wild  entertainment\n",
              "2965  irish scientist identify covid patient develop...         health\n",
              "2977  marjorie taylor greene sorry likening mask hol...       politics\n",
              "\n",
              "[147 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cgabdZR3Vvt",
        "outputId": "c1948845-c080-460e-edd0-e18c95a1e01e"
      },
      "source": [
        "idx = [124, 162, 174, 184, 185, 292, 460, 464, 521, 527, 574, 588, 625, 705, 763, 842, 854, 901, 902, 1006, 1043, 1050, 1102, 1274, 1326, 1381, 1396, 1404, 1409, 1619, 1656, 1867, 1882, 1884, 2025, 2100, 2266, 2277, 2311, 2329, 2365, 2441, 2655, 2742, 2811, 2902, 2913, 2943, 2965, 2977]\n",
        "print(len(idx))\n",
        "test_data_temp = test_data.copy()\n",
        "test_data_temp = test_data_temp.drop(idx, axis=0)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgDwHHxRSvcG",
        "outputId": "dc36bbcf-8f86-4beb-d80c-9b142e6ad649"
      },
      "source": [
        "predicted_temp = tweet_clf.predict(test_data_temp['text'])\n",
        "print('We got an accuracy of', np.mean(predicted_temp == test_data_temp['category']) * 100, '% over the test data.')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We got an accuracy of 82.36363636363636 % over the test data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7fC0bFUBxXa"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0FHx0CYByqR"
      },
      "source": [
        "classifier_model = pickle.dumps(tweet_clf)"
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}